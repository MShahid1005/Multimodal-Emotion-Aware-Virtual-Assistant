# Multimodal Emotion Aware Virtual Assistant

This project is my Final Year Project (FYP) A smart virtual assistant capable of understanding and responding to user emotions using speech, facial expressions, and text sentiment analysis.  
It is built using Flutter for cross-platform UI, integrated with AI/ML models for emotion detection.

---

## üöÄ Features
- **Speech Recognition** ‚Äì Understands and processes voice commands.
- **Facial Emotion Detection** ‚Äì Detects emotions through facial expressions.
- **Real-time Interaction** ‚Äì Responds instantly with context-aware behavior.

---

## üõ†Ô∏è Tech Stack
- **Frontend:** Flutter (Dart)
- **Backend/Processing:** Python (for ML models)
- **ML/AI Models:** Emotion detection (Facial + Speech + Text)
- **Tools & APIs:** TensorFlow, OpenCV, Speech-to-Text APIs

---
## Install Flutter dependencies:
flutter pub get


## Run the app
flutter run

## Interface
![SignUp_Page](https://github.com/user-attachments/assets/9a416c8c-ca8b-4069-846b-2607ac52d427)
![Home_Page](https://github.com/user-attachments/assets/cfd505ca-0c16-477c-ae31-a74214525e61)
![Camera_Screen](https://github.com/user-attachments/assets/6e098627-406c-4c36-8636-319f86b4c45d)
![drawer_Screen](https://github.com/user-attachments/assets/61e675a8-4bdb-4e54-b848-5a9b099dd043)
![Setting_Screen](https://github.com/user-attachments/assets/6731875b-89c3-4950-81d5-c3b823c33c34)
![History_Screen](https://github.com/user-attachments/assets/050adf83-05c6-421b-85cb-93a74b743301)

