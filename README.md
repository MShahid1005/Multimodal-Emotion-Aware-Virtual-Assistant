# Multimodal Emotion Aware Virtual Assistant

This project is my Final Year Project (FYP) A smart virtual assistant capable of understanding and responding to user emotions using speech, facial expressions, and text sentiment analysis.  
It is built using Flutter for cross-platform UI, integrated with AI/ML models for emotion detection.

---

## üöÄ Features
- **Speech Recognition** ‚Äì Understands and processes voice commands.
- **Facial Emotion Detection** ‚Äì Detects emotions through facial expressions.
- **Real-time Interaction** ‚Äì Responds instantly with context-aware behavior.

---

## üõ†Ô∏è Tech Stack
- **Frontend:** Flutter (Dart)
- **Backend/Processing:** Python (for ML models)
- **ML/AI Models:** Emotion detection (Facial + Speech + Text)
- **Tools & APIs:** TensorFlow, OpenCV, Speech-to-Text APIs

---
## Install Flutter dependencies:
flutter pub get

## Run the app
flutter run



