# Multimodal Emotion Aware Virtual Assistant

This project is my Final Year Project (FYP) A smart virtual assistant capable of understanding and responding to user emotions using speech, facial expressions, and text sentiment analysis.  
It is built using Flutter for cross-platform UI, integrated with AI/ML models for emotion detection.

---

## üöÄ Features
- **Speech Recognition** ‚Äì Understands and processes voice commands.
- **Facial Emotion Detection** ‚Äì Detects emotions through facial expressions.
- **Real-time Interaction** ‚Äì Responds instantly with context-aware behavior.

---

## üõ†Ô∏è Tech Stack
- **Frontend:** Flutter (Dart)
- **Backend/Processing:** Python (for ML models)
- **ML/AI Models:** Emotion detection (Facial + Speech + Text)
- **Tools & APIs:** TensorFlow, OpenCV, Speech-to-Text APIs

---
## Install Flutter dependencies:
flutter pub get


## Run the app
flutter run

## App Interface
![Login_Page](https://github.com/user-attachments/assets/806e97a1-378c-4603-9293-fbed943fcd39)
![SignUp_Page](https://github.com/user-attachments/assets/5e9a932e-551d-4d6c-97fd-41a3ed819de1)
![Home_Page](https://github.com/user-attachments/assets/e724cdcf-157f-4dc7-ba9a-db6c503aeffb)
![Camera_Screen](https://github.com/user-attachments/assets/0fbe5108-7254-435b-91d8-356300c5a79f)
![drawer_Screen](https://github.com/user-attachments/assets/fa80c9cb-16bf-476e-b50c-118bc9327286)
![Setting_Screen](https://github.com/user-attachments/assets/c7b6921f-673b-42e1-8180-9e7baf9867cd)
![History_Screen](https://github.com/user-attachments/assets/9cc576b1-a517-49aa-a45a-56da4dd2eff4)
![Recent_Emotion_Screen](https://github.com/user-attachments/assets/a75253c0-2dce-428b-a1ef-c5e40f8a2134)
![Graph_Screen](https://github.com/user-attachments/assets/e030a77c-44dc-400c-ae40-fb54460a10c2)


